{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Anti-Echo Chamber - Article Comparison Tool\n",
        "\n",
        "This notebook compares news articles and finds opposing viewpoints to break echo chambers.\n",
        "\n",
        "**Key Features:**\n",
        "- Query similar articles by topic\n",
        "- Find opposing viewpoints by political stance\n",
        "- Interactive article comparison\n",
        "- ChromaDB-based retrieval system\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/AHMerrill/anti-echo-2/blob/master/notebooks/anti_echo_chamber.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q chromadb sentence-transformers transformers huggingface-hub datasets scikit-learn nltk pyyaml\n",
        "\n",
        "# Set environment variables\n",
        "import os\n",
        "import torch\n",
        "os.environ[\"CHROMA_TELEMETRY_ENABLED\"] = \"false\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
        "\n",
        "# GPU/CPU Detection and Configuration\n",
        "def setup_device():\n",
        "    \"\"\"Detect and configure device for optimal performance.\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        device = \"cuda\"\n",
        "        print(f\"üöÄ GPU detected: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    else:\n",
        "        device = \"cpu\"\n",
        "        print(\"üíª Using CPU (GPU not available)\")\n",
        "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "    \n",
        "    print(f\"‚úÖ Device configured: {device}\")\n",
        "    return device\n",
        "\n",
        "# Setup device\n",
        "device = setup_device()\n",
        "\n",
        "# Manual device override (uncomment if needed)\n",
        "# device = \"cpu\"  # Force CPU usage\n",
        "# device = \"cuda\"  # Force GPU usage (if available)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download Core Library and Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the core library and configs from GitHub\n",
        "!git clone https://github.com/AHMerrill/anti-echo-2.git temp_repo\n",
        "!cp -r temp_repo/* ./\n",
        "!rm -rf temp_repo\n",
        "\n",
        "# Load the core system\n",
        "from anti_echo_core import AntiEchoCore\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Initialize the core system with detected device\n",
        "print(\"Initializing Anti-Echo Chamber system...\")\n",
        "core = AntiEchoCore(\"config/config.yaml\", device=device)\n",
        "print(f\"‚úì System initialized successfully on {core.device}\")\n",
        "\n",
        "print(\"üìñ Comparison tool ready - no authentication needed (read-only)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data from Hugging Face and Recreate ChromaDB\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_data_and_recreate_chroma(dataset_name=\"anti-echo-chamber-data\"):\n",
        "    \"\"\"Load data from Hugging Face and recreate ChromaDB for querying.\"\"\"\n",
        "    \n",
        "    print(f\"üì• Loading data from Hugging Face dataset: {dataset_name}\")\n",
        "    \n",
        "    try:\n",
        "        # Load the dataset\n",
        "        dataset = load_dataset(dataset_name, split=\"train\")\n",
        "        print(f\"‚úì Loaded {len(dataset)} articles from Hugging Face\")\n",
        "        \n",
        "        # Convert to list of dictionaries\n",
        "        articles = []\n",
        "        for item in dataset:\n",
        "            articles.append(dict(item))\n",
        "        \n",
        "        print(f\"üìä Recreating ChromaDB with {len(articles)} articles...\")\n",
        "        \n",
        "        # Clear existing collections\n",
        "        try:\n",
        "            core.chroma_client.delete_collection(\"news_topic\")\n",
        "            core.chroma_client.delete_collection(\"news_stance\")\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        # Recreate collections\n",
        "        core.topic_coll = core.chroma_client.create_collection(\n",
        "            name=\"news_topic\",\n",
        "            metadata={\"hnsw:space\": \"cosine\"}\n",
        "        )\n",
        "        core.stance_coll = core.chroma_client.create_collection(\n",
        "            name=\"news_stance\", \n",
        "            metadata={\"hnsw:space\": \"cosine\"}\n",
        "        )\n",
        "        \n",
        "        # Recreate ChromaDB from HF data\n",
        "        for i, article in enumerate(articles):\n",
        "            if i % 50 == 0:\n",
        "                print(f\"  Processing {i}/{len(articles)} articles...\")\n",
        "            \n",
        "            # Reconstruct the processed article format\n",
        "            processed_article = {\n",
        "                \"id\": article[\"id\"],\n",
        "                \"title\": article[\"title\"],\n",
        "                \"url\": article[\"url\"],\n",
        "                \"source\": article[\"source\"],\n",
        "                \"published\": article[\"published\"],\n",
        "                \"topics\": article[\"topics\"],\n",
        "                \"political_leaning\": article[\"political_leaning\"],\n",
        "                \"implied_stance\": article[\"implied_stance\"],\n",
        "                \"summary\": article[\"summary\"],\n",
        "                \"topic_vectors\": article[\"topic_vectors\"],\n",
        "                \"stance_embedding\": article[\"stance_embedding\"],\n",
        "                \"text_length\": article[\"text_length\"]\n",
        "            }\n",
        "            \n",
        "            # Upsert to ChromaDB\n",
        "            core.upsert_to_chroma(processed_article)\n",
        "        \n",
        "        print(f\"‚úÖ ChromaDB recreated successfully with {len(articles)} articles\")\n",
        "        return articles\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading data: {e}\")\n",
        "        print(\"Make sure the dataset exists and you have access to it\")\n",
        "        return []\n",
        "\n",
        "# Load the data\n",
        "# You can change the dataset name here if needed\n",
        "dataset_name = \"zanimal/anti-echo-chamber-data\"  # Default dataset\n",
        "# dataset_name = input(\"Enter dataset name (or press Enter for default): \").strip() or \"zanimal/anti-echo-chamber-data\"\n",
        "\n",
        "articles = load_data_and_recreate_chroma(dataset_name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Article Comparison Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_similar_articles(query_text, n_results=5):\n",
        "    \"\"\"Find articles with similar topics (by topic overlap count).\"\"\"\n",
        "    print(f\"üîç Finding articles with similar topics to: '{query_text[:100]}...'\")\n",
        "    \n",
        "    similar_articles = core.query_similar_articles(query_text, n_results)\n",
        "    \n",
        "    if similar_articles:\n",
        "        print(f\"\\nüì∞ Found {len(similar_articles)} articles with topic overlap:\")\n",
        "        for i, article in enumerate(similar_articles, 1):\n",
        "            print(f\"\\n{i}. {article['title']}\")\n",
        "            print(f\"   Source: {article['source']}\")\n",
        "            print(f\"   Political Leaning: {article['political_leaning']}\")\n",
        "            print(f\"   Implied Stance: {article['implied_stance']}\")\n",
        "            print(f\"   Topics: {', '.join(article['topics'])}\")\n",
        "            print(f\"   URL: {article['url']}\")\n",
        "    else:\n",
        "        print(\"No articles with topic overlap found\")\n",
        "    \n",
        "    return similar_articles\n",
        "\n",
        "def find_opposing_articles(query_text, n_results=5):\n",
        "    \"\"\"Find articles with opposing political stance (cosine similarity, ascending order).\"\"\"\n",
        "    print(f\"‚öñÔ∏è Finding opposing viewpoints to: '{query_text[:100]}...'\")\n",
        "    print(\"   (Ranked by stance dissimilarity - most opposing first)\")\n",
        "    \n",
        "    opposing_articles = core.query_opposing_stance(query_text, n_results)\n",
        "    \n",
        "    if opposing_articles:\n",
        "        print(f\"\\nüì∞ Found {len(opposing_articles)} opposing articles (most dissimilar first):\")\n",
        "        for i, article in enumerate(opposing_articles, 1):\n",
        "            print(f\"\\n{i}. {article['title']}\")\n",
        "            print(f\"   Source: {article['source']}\")\n",
        "            print(f\"   Political Leaning: {article['political_leaning']}\")\n",
        "            print(f\"   Implied Stance: {article['implied_stance']}\")\n",
        "            print(f\"   Summary: {article['summary']}\")\n",
        "            print(f\"   URL: {article['url']}\")\n",
        "    else:\n",
        "        print(\"No opposing articles found\")\n",
        "    \n",
        "    return opposing_articles\n",
        "\n",
        "def compare_articles(article1_text, article2_text):\n",
        "    \"\"\"Compare two articles side by side.\"\"\"\n",
        "    print(\"üìä Article Comparison\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Process both articles\n",
        "    article1 = core.process_article({\"text\": article1_text, \"title\": \"Article 1\"})\n",
        "    article2 = core.process_article({\"text\": article2_text, \"title\": \"Article 2\"})\n",
        "    \n",
        "    if not article1 or not article2:\n",
        "        print(\"Error processing articles\")\n",
        "        return\n",
        "    \n",
        "    print(f\"\\nüì∞ Article 1:\")\n",
        "    print(f\"   Political Leaning: {article1['political_leaning']}\")\n",
        "    print(f\"   Implied Stance: {article1['implied_stance']}\")\n",
        "    print(f\"   Topics: {', '.join(article1['topics'])}\")\n",
        "    print(f\"   Summary: {article1['summary']}\")\n",
        "    \n",
        "    print(f\"\\nüì∞ Article 2:\")\n",
        "    print(f\"   Political Leaning: {article2['political_leaning']}\")\n",
        "    print(f\"   Implied Stance: {article2['implied_stance']}\")\n",
        "    print(f\"   Topics: {', '.join(article2['topics'])}\")\n",
        "    print(f\"   Summary: {article2['summary']}\")\n",
        "    \n",
        "    # Calculate similarity\n",
        "    from sklearn.metrics.pairwise import cosine_similarity\n",
        "    similarity = cosine_similarity(\n",
        "        [article1['stance_embedding']], \n",
        "        [article2['stance_embedding']]\n",
        "    )[0][0]\n",
        "    \n",
        "    print(f\"\\nüîç Stance Similarity: {similarity:.3f}\")\n",
        "    \n",
        "    if article1['political_leaning'] != article2['political_leaning']:\n",
        "        print(\"‚öñÔ∏è Different political leanings - potential opposing viewpoints!\")\n",
        "    else:\n",
        "        print(\"ü§ù Similar political leanings\")\n",
        "    \n",
        "    return article1, article2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example Usage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 1: Find similar articles\n",
        "query = \"climate change policy\"\n",
        "similar = find_similar_articles(query, n_results=3)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# Example 2: Find opposing viewpoints\n",
        "opposing = find_opposing_articles(query, n_results=3)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "# Example 3: Compare two specific articles\n",
        "article1_text = \"The government should implement strict climate regulations to reduce carbon emissions.\"\n",
        "article2_text = \"Free market solutions are better than government regulations for addressing climate change.\"\n",
        "\n",
        "compare_articles(article1_text, article2_text)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
